---
title: "Module9"
format: html
editor: visual
---

```{r}
library(curl)
```

```{r}
n <- 1000
mu <- 3.5
sigma <- 4
v <- rnorm(n, mu, sigma)
s <- sample(v, size = 30, replace = FALSE)
m <- mean(s)
m
```

```{r}
sd <- sd(s)
sd
```

```{r}
sem <- sd(s)/sqrt(length(s))
sem
```

```{r}
lower <- m - qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- m + qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci <- c(lower, upper)
ci
```

# Central Limit Theorem

```{r}
lambda <- 14
n <- 10
pop_se <- sqrt(lambda/n)  # the estimated SE
pop_se
```

## n = 10
```{r}
x <- NULL
for (i in 1:1000) {
    x[i] <- mean(rpois(n = n, lambda = lambda))
}
hist(x, breaks = seq(from = lambda - 4 * sqrt(lambda)/sqrt(n), to = lambda +
    4 * sqrt(lambda)/sqrt(n), length.out = 20), probability = TRUE)
```

```{r}
sd <- sd(x)  # st dev of the sampling distribution
sd
```

```{r}
qqnorm(x)
qqline(x)
```

## n = 100
```{r}
n <- 100
pop_se <- sqrt(lambda/n)  # the estimated SE
pop_se
```

```{r}
x <- NULL
for (i in 1:1000) {
    x[i] <- mean(rpois(n = n, lambda = lambda))
}
hist(x, breaks = seq(from = lambda - 4 * sqrt(lambda)/sqrt(n), to = lambda +
    4 * sqrt(lambda)/sqrt(n), length.out = 20), probability = TRUE)
```

```{r}
sd <- sd(x)  # st dev of the sampling distribution
sd
```

```{r}
qqnorm(x)
qqline(x)
```

We can convert these distributions to standard normals by subtracting off the expected population mean (ðœ†
) and dividing by the standard error of the mean (an estimate of the standard deviation of the sampling distribution) and then plotting a histogram of those values along with a normal curve.

```{r}
curve(dnorm(x, 0, 1), -4, 4, ylim = c(0, 0.8))
z <- (x - lambda)/pop_se
hist(z, breaks = seq(from = -4, to = 4, length.out = 20), probability = TRUE,
    add = TRUE)
```

Pretty normal looking, right?

Hereâ€™s an example of the CLT in action using sum() instead of mean()â€¦

```{r}
n <- 100
x <- NULL
for (i in 1:1000) {
    x[i] <- sum(rpois(n = n, lambda = lambda))
}
hist(x, breaks = seq(min(x), max(x), length.out = 20), probability = TRUE)
```

# Confidence Intervals for Sample Proportions

## Challenge
Suppose a polling group in the Massachusetts is interested in the proportion of voting-age citizens in their state that already know they will vote for Elizabeth Warren in the upcoming November 5, 2024 general elections (donâ€™t forget to vote!). The group obtains a yes or no answer from 1000 suitable randomly selected individuals. Of these individuals, 856 say they know theyâ€™ll vote for Senator Warren. How would we characterize the mean and variability associated with this proportion?

```{r}
n <- 1000
x <- 856
phat <- x/n  # our estimate of pi
phat
```

```{r}
n * phat
```

```{r}
n * (1 - phat)
```

```{r}
pop_se <- sqrt((phat) * (1 - phat)/n)
```

```{r}
curve(dnorm(x, mean = phat, sd = pop_se), phat - 4 * pop_se, phat + 4 * pop_se)
upper <- phat + qnorm(0.975) * pop_se
lower <- phat - qnorm(0.975) * pop_se
ci <- c(lower, upper)
polygon(cbind(c(ci[1], seq(from = ci[1], to = ci[2], length.out = 1000), ci[2]),
    c(0, dnorm(seq(from = ci[1], to = ci[2], length.out = 1000), mean = phat,
        sd = pop_se), 0)), border = "black", col = "gray")
abline(v = ci)
abline(h = 0)
```

# Small Sample Confidence Intervals

```{r}
mu <- 0
sigma <- 1
curve(dnorm(x, mu, 1), mu - 4 * sigma, mu + 4 * sigma, main = "Normal Curve=red\nStudent's t=blue",
    xlab = "x", ylab = "f(x)", col = "red", lwd = 3)
for (i in c(1, 2, 3, 4, 5, 10, 20, 100)) {
    curve(dt(x, df = i), mu - 4 * sigma, mu + 4 * sigma, main = "T Curve", xlab = "x",
        ylab = "f(x)", add = TRUE, col = "blue", lty = 5)
}
```

```{r}
n <- 1e+05
mu <- 3.5
sigma <- 4
x <- rnorm(n, mu, sigma)
sample_size <- 30
s <- sample(x, size = sample_size, replace = FALSE)
m <- mean(s)
m
```

```{r}
sd <- sd(s)
sd
```

```{r}
sem <- sd(s)/sqrt(length(s))
sem
```

```{r}
lower <- m - qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- m + qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci_norm <- c(lower, upper)
ci_norm
```

```{r}
lower <- m - qt(1 - 0.05/2, df = sample_size - 1) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- m + qt(1 - 0.05/2, df = sample_size - 1) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci_t <- c(lower, upper)
ci_t
```

However, if we use a sample size of 5, the CI based on the t distribution is much wider.

```{r}
sample_size <- 5
s <- sample(x, size = sample_size, replace = FALSE)
m <- mean(s)
m
```

```{r}
sd <- sd(s)
sd
```

```{r}
sem <- sd(s)/sqrt(length(s))
sem
```

```{r}
lower <- m - qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- m + qnorm(1 - 0.05/2) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci_norm <- c(lower, upper)
ci_norm
```

```{r}
lower <- m - qt(1 - 0.05/2, df = sample_size - 1) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- m + qt(1 - 0.05/2, df = sample_size - 1) * sem  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci_t <- c(lower, upper)
ci_t
```





